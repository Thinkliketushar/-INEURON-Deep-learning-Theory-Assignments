{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6bd03c",
   "metadata": {},
   "source": [
    "# Assignment 02 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a248256",
   "metadata": {},
   "source": [
    "#### 1.\tDescribe the structure of an artificial neuron. How is it similar to a biological neuron? What are its main components?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604711b",
   "metadata": {},
   "source": [
    "<code>An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human body's biological neural network, have a layered architecture and each network node (connection point) has the capability to process input and forward output to other nodes in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5f184",
   "metadata": {},
   "source": [
    "#### 2.\tWhat are the different types of activation functions popularly used? Explain each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10ba64",
   "metadata": {},
   "source": [
    "<code>The basic rule of thumb is if you really don't know what activation function to use, then simply use RELU as it is a general activation function in hidden layers and is used in most cases these days. If your output is for binary classification then, sigmoid function is very natural choice for output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7aaa4",
   "metadata": {},
   "source": [
    "#### Explain the below statements ?\n",
    "1.\tExplain, in details, Rosenblatt’s perceptron model. How can a set of data be classified using a simple perceptron?\n",
    "2.\tUse a simple perceptron with weights w0, w1, and w2 as −1, 2, and 1, respectively, to classify data points (3, 4); (5, 2); (1, −3); (−8, −3); (−3, 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fea5e7f",
   "metadata": {},
   "source": [
    "<code>The inputs integration is implemented through the addition of the weighted inputs that have fixed weights obtained during the training stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746cb7cc",
   "metadata": {},
   "source": [
    "#### 4.\tExplain the basic structure of a multi-layer perceptron. Explain how it can solve the XOR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b2cb76",
   "metadata": {},
   "source": [
    "<code>We call this extra layer as the Hidden layer. To build a perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8aca2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "[0.693148136138916, 0.5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# XOR inputs and outputs\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs = np.array([[0], [1], [1], [0]])\n",
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "# Add layers\n",
    "model.add(Dense(2, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(inputs, outputs, epochs=5000, verbose=0)\n",
    "# Evaluate the model\n",
    "print(model.evaluate(inputs, outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cbd41",
   "metadata": {},
   "source": [
    "#### 5.\tWhat is artificial neural network (ANN)? Explain some of the salient highlights in the different architectural options for ANN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e6948",
   "metadata": {},
   "source": [
    "<code>An Artificial Neural Network (ANN) is a machine learning model inspired by the human brain's neural structure. It comprises interconnected nodes (neurons) organized into layers. Data flows through these nodes, adjusting the weights of connections to learn patterns and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e479268",
   "metadata": {},
   "source": [
    "#### 6.\tExplain the learning process of an ANN. Explain, with example, the challenge in assigning synaptic weights for the interconnection between neurons? How can this challenge be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad7e409",
   "metadata": {},
   "source": [
    "<code>learning Process:- deciding the number of hidden layers, the number of nodes in each of the hidden layers, the direction of signal flow, deciding the connection weight. Synaptic weight refers to the strength or amplitude of a connection between two nodes, corresponding in biology to the amount of influence the firing of one neuron has on another. We assign weights using diffrent technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71bd58a",
   "metadata": {},
   "source": [
    "#### 7.\tExplain, in details, the backpropagation algorithm. What are the limitations of this algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62dba14",
   "metadata": {},
   "source": [
    "<code>Backpropagation, or backward propagation of errors, is an algorithm that is designed to test for errors working back from output nodes to input nodes and finding weights using otimiser technique.\n",
    "Backpropagation could be rather sensitive to noisy data and irregularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d16db75",
   "metadata": {},
   "source": [
    "#### 8.\tDescribe, in details, the process of adjusting the interconnection weights in a multi-layer neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a32a086",
   "metadata": {},
   "source": [
    "<code>It is a supervised learning algorithm which continues adjusting the weights of the connected neurons with an objective to reduce the deviation of the output signal from the target output. This algorithm consists of multiple iterations, known as epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e3af2",
   "metadata": {},
   "source": [
    "#### 9.\tWhat are the steps in the backpropagation algorithm? Why a multi-layer neural network is required?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31373642",
   "metadata": {},
   "source": [
    "<code>Step 1: Inputs X, arrive through the preconnected path.\n",
    "Step 2: The input is modeled using true weights W. Weights are usually chosen randomly.\n",
    "Step 3: Calculate the output of each neuron from the input layer to the hidden layer to the output layer.\n",
    "Step 4: Calculate the error in the outputs\n",
    "Step 5: From the output layer, go back to the hidden layer to adjust the weights to reduce the error.\n",
    "Step 6: Repeat the process until the desired output is achieved.\n",
    "To recalculate the weights array w in the last neuron layer, and proceed this way towards the previous layers, from back to front, that is, to update all the weights w in each layer, from the last one until reaching the input layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77bd31",
   "metadata": {},
   "source": [
    "#### 10.\tWrite short notes on:\n",
    "1.\tArtificial neuron\n",
    "2.\tMulti-layer perceptron\n",
    "3.\tDeep learning\n",
    "4.\tLearning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4a115",
   "metadata": {},
   "source": [
    "<code>Artificial neuron:- An artificial neuron is a connection point in an artificial neural network.\n",
    "Multi-layer perceptron:- many layers of ANN.\n",
    "Deep learning:- Leaening in which model learn like human.\n",
    "Learning rate:-  hyper-parameter used to govern the pace at which an algorithm updates or learns the values of a parameter estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f89d0c9",
   "metadata": {},
   "source": [
    "#### 11.\tWrite the difference between:-\n",
    "1.\tActivation function vs threshold function\n",
    "2.\tStep function vs sigmoid function\n",
    "3.\tSingle layer vs multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f7fc6",
   "metadata": {},
   "source": [
    "<code>Activation function vs threshold function:- Threshold activation function (or simply the activation function, also known as squashing function) results in an output signal only when an input signal exceeding a specific threshold value comes as an input. The activation function compares the input value to a threshold value.\n",
    "Step function vs sigmoid function:- The step activation function is a good choice for binary classification problems where the goal is to produce a binary output. The sigmoid activation function is a good choice for multi-class classification problems where the goal is to produce a continuous output\n",
    "Single layer vs multi-layer perceptron:- A single-layer perceptron can only learn linear functions, but Multilayered Perceptrons can also learn non-linear functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01c0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
